{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    fo = open(filename, 'rb')\n",
    "    fdict = cPickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return fdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for i in range(1, 6):\n",
    "    data_dict['data_batch_' + str(i)] = unpickle('cucumber_data/p1/data_batch_' + str(i))\n",
    "data_dict['test_batch'] = unpickle('cucumber_data/p1/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images(data, labels):\n",
    "    num_images = data.shape[0] // 3\n",
    "    images = np.zeros((num_images, 32*32*3))\n",
    "    labels_arr = np.zeros((num_images, 9))\n",
    "    for i in range(num_images):\n",
    "        images[i] = np.hstack((data[3*i], data[3*i+1], data[3*i+2])) / 255\n",
    "        labels_arr[i][labels[i]] = 1\n",
    "    return (images, labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_dict = {}\n",
    "labels_dict = {}\n",
    "for data_batch in data_dict:\n",
    "    images_dict[data_batch], labels_dict[data_batch] = get_images(data_dict[data_batch]['data'], data_dict[data_batch]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_images = images_dict['data_batch_5']\n",
    "validation_labels = labels_dict['data_batch_5']\n",
    "\n",
    "test_images = images_dict['test_batch']\n",
    "test_labels = labels_dict['test_batch']\n",
    "\n",
    "train_images = np.vstack((images_dict['data_batch_1'], \n",
    "                          images_dict['data_batch_2'], \n",
    "                          images_dict['data_batch_3'], \n",
    "                          images_dict['data_batch_4']))\n",
    "\n",
    "train_labels = np.vstack((labels_dict['data_batch_1'], \n",
    "                          labels_dict['data_batch_2'], \n",
    "                          labels_dict['data_batch_3'], \n",
    "                          labels_dict['data_batch_4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 3072)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(images, batch_size):\n",
    "    images_ind = list(range(len(images)))\n",
    "    random.shuffle(images_ind)\n",
    "    return images[images_ind[:batch_size]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 32*32*3\n",
    "neuron_1 = 300\n",
    "neuron_2 = 300\n",
    "# neuron_3 = 100\n",
    "# neuron_4 = 50\n",
    "\n",
    "learning_rate = 1e-4\n",
    "num_train_examples = train_images.shape[0]\n",
    "iters = 10*num_train_examples\n",
    "batch_size = 100\n",
    "num_subjects = 9\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=[None, input_size], dtype=tf.float32)\n",
    "y_correct = tf.placeholder(shape=[None, num_subjects], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_1 = tf.Variable(tf.truncated_normal(shape=[input_size, neuron_1], stddev=0.1))\n",
    "b_1 = tf.Variable(tf.truncated_normal(shape=[neuron_1], stddev=0.1))\n",
    "\n",
    "z_1 = tf.add(tf.matmul(x, W_1), b_1)\n",
    "a_1 = tf.nn.dropout(tf.nn.relu(z_1), keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_2 = tf.Variable(tf.truncated_normal(shape=[neuron_1, neuron_2], stddev=0.1))\n",
    "b_2 = tf.Variable(tf.truncated_normal(shape=[neuron_2], stddev=0.1))\n",
    "\n",
    "z_2 = tf.add(tf.matmul(a_1, W_2), b_2)\n",
    "a_2 = tf.nn.dropout(tf.nn.relu(z_2), keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### 3 layers\n",
    "#W_3 = tf.Variable(tf.truncated_normal(shape=[neuron_2, neuron_3], stddev=0.1))\n",
    "#b_3 = tf.Variable(tf.truncated_normal(shape=[neuron_3], stddev=0.1))\n",
    "#z_3 = tf.add(tf.matmul(a_2, W_3), b_3)\n",
    "#a_3 = tf.nn.dropout(tf.nn.relu(z_3), keep_prob=keep_prob)\n",
    "#W_4 = tf.Variable(tf.truncated_normal(shape=[neuron_3, num_subjects], stddev=0.1))\n",
    "#b_4 = tf.Variable(tf.truncated_normal(shape=[num_subjects], stddev=0.1))\n",
    "#y = tf.add(tf.matmul(a_3, W_4), b_4)\n",
    "##### End of 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### 2 layers\n",
    "W_3 = tf.Variable(tf.truncated_normal(shape=[neuron_2, num_subjects], stddev=0.1))\n",
    "b_3 = tf.Variable(tf.truncated_normal(shape=[num_subjects], stddev=0.1))\n",
    "y = tf.add(tf.matmul(a_2, W_3), b_3)\n",
    "##### End of 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### 4 layers\n",
    "# W_3 = tf.Variable(tf.truncated_normal(shape=[neuron_2, neuron_3], stddev=0.1))\n",
    "# b_3 = tf.Variable(tf.truncated_normal(shape=[neuron_3], stddev=0.1))\n",
    "# z_3 = tf.add(tf.matmul(a_2, W_3), b_3)\n",
    "# a_3 = tf.nn.relu(z_3)\n",
    "# W_4 = tf.Variable(tf.truncated_normal(shape=[neuron_3, neuron_4], stddev=0.1))\n",
    "# b_4 = tf.Variable(tf.truncated_normal(shape=[neuron_4], stddev=0.1))\n",
    "# z_4 = tf.add(tf.matmul(a_3, W_4), b_4)\n",
    "# a_4 = tf.nn.relu(z_4)\n",
    "# W_5 = tf.Variable(tf.truncated_normal(shape=[neuron_4, num_subjects], stddev=0.1))\n",
    "# b_5 = tf.Variable(tf.truncated_normal(shape=[num_subjects], stddev=0.1))\n",
    "# y = tf.add(tf.matmul(a_4, W_5), b_5)\n",
    "##### End of 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels = y_correct))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_correct,1), name = \"correct_prediction\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "validation_feed_dict = {x: validation_images, y_correct: validation_labels, keep_prob:1.0 }\n",
    "test_feed_dict = {x: test_images, y_correct: test_labels, keep_prob:1.0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0\n",
      "Train accuracy: 0.12999999523162842\n",
      "Validation accuracy: 0.111111119389534\n",
      "STEP 2000\n",
      "Train accuracy: 0.6299999356269836\n",
      "Validation accuracy: 0.6727272868156433\n",
      "STEP 4000\n",
      "Train accuracy: 0.7599999904632568\n",
      "Validation accuracy: 0.7191920280456543\n",
      "STEP 6000\n",
      "Train accuracy: 0.8199999332427979\n",
      "Validation accuracy: 0.7494949698448181\n",
      "STEP 8000\n",
      "Train accuracy: 0.8399999737739563\n",
      "Validation accuracy: 0.765656590461731\n",
      "STEP 10000\n",
      "Train accuracy: 0.9200000166893005\n",
      "Validation accuracy: 0.7838383913040161\n",
      "STEP 12000\n",
      "Train accuracy: 0.9200000762939453\n",
      "Validation accuracy: 0.7737374305725098\n",
      "STEP 14000\n",
      "Train accuracy: 0.9099999666213989\n",
      "Validation accuracy: 0.7757576704025269\n",
      "STEP 16000\n",
      "Train accuracy: 0.9600000381469727\n",
      "Validation accuracy: 0.7838384509086609\n",
      "STEP 18000\n",
      "Train accuracy: 0.9300000071525574\n",
      "Validation accuracy: 0.7757575511932373\n",
      "DONE. Test accuracy: 0.802020251750946\n"
     ]
    }
   ],
   "source": [
    "for i in range(iters):\n",
    "    train_indices = random.sample(range(num_train_examples), batch_size)\n",
    "    train_feed_dict = {x: train_images[train_indices], y_correct: train_labels[train_indices], keep_prob:0.7 }\n",
    "    if i%2000 == 0:\n",
    "        # print accuracy\n",
    "        train_acc = sess.run(accuracy, feed_dict=train_feed_dict)\n",
    "        validation_acc = sess.run(accuracy, feed_dict=validation_feed_dict)\n",
    "        print(\"STEP {}\".format(i))\n",
    "        print(\"Train accuracy: {}\".format(train_acc))\n",
    "        print(\"Validation accuracy: {}\".format(validation_acc))\n",
    "\n",
    "    _ = sess.run(train_step, feed_dict = train_feed_dict)\n",
    "\n",
    "test_acc = sess.run(accuracy, feed_dict=test_feed_dict)\n",
    "print(\"DONE. Test accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
