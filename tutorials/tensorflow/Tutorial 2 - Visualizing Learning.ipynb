{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Learning and Graph Visualization\n",
    "\n",
    "This tutorial is taken from \"Hello, Tensorflow\" by Aaron Schumacher, 2016.\n",
    "\n",
    "From the first tutorial, we have built a neuron that takes the input 1.0 and returns 0.8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.constant(1.0, name='input')\n",
    "w = tf.Variable(0.8, name='weight')\n",
    "y = tf.mul(w, x, name='output')\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say the correct output should be zero. In short, we have a very simple training set of just one example with one feature (which has value one) and one label (zero). We want this neuron to learn the function taking one to zero.\n",
    "\n",
    "The system is not working perfectly, it returns 0.8 instead of zero, given the input of 1.0. We will use \"loss\" as a measure of how \"wrong\"\" the system is.\n",
    "\n",
    "In you opinion, what are some ways to measure this \"loss\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to define \"loss\" is taking the square of the difference between the current output and the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'pow:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = tf.constant(0.0)\n",
    "loss = (y - y_)**2\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the value of \"loss\" in this example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64000005"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help the graph to learn, we need an [optimizer](https://www.tensorflow.org/api_docs/python/train/optimizers). We'll use a [gradient descent optimizer](https://www.tensorflow.org/api_docs/python/train/optimizers#GradientDescentOptimizer) that we can update the weight based on the derivative of the loss.\n",
    "What is the derivative of the loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer takes a learning rate to moderate the size of the updates, which weâ€™ll set at 0.025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, <tensorflow.python.ops.variables.Variable at 0xc622d297f0>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0xc6264db898>),\n",
       " (<tf.Tensor 'gradients_7/output_2_grad/tuple/control_dependency:0' shape=() dtype=float32>,\n",
       "  <tensorflow.python.ops.variables.Variable at 0xc61dbde4e0>)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = tf.train.GradientDescentOptimizer(learning_rate=0.025)\n",
    "grads_and_vars = optim.compute_gradients(loss)\n",
    "grads_and_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer applies the appropriate gradients through a whole network, carrying out the backward step for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(grads_and_vars[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value of the gradient should match your answer above, which is the derivative of the loss function at 0.8.\n",
    "Let's apply the gradient to finish the backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(optim.apply_gradients(grads_and_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the updated weight of this neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the initial weight of 0.8, this updated weight is 0.04 lower. Does the decrease make sense? Why a decrease of 0.4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the system learn multiple times, we can make one operation that calculates and applies the gradients: the train_step, and execute the train_step operation as many times as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.025).minimize(loss)\n",
    "for i in range(100):\n",
    "    sess.run(train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just run the train_step 100 times. Let's check if the current output is closer to the desired one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0044996012"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y) # current output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the initial output of 0.8, the updated output after many train steps is closer to zero - the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0044996012"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(w) # current weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will happen to the output if we increase the iteration of train_step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add in more code to see the output after each train_step in the following format:\n",
    "\n",
    "before step 0, y is 0.800000011921\n",
    "\n",
    "before step 1, y is 0.759999990463\n",
    "\n",
    "...\n",
    "\n",
    "before step 98, y is 0.00524811353534\n",
    "\n",
    "before step 99, y is 0.00498570781201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before step 0, y is 0.800000011920929\n",
      "before step 1, y is 0.7599999904632568\n",
      "before step 2, y is 0.722000002861023\n",
      "before step 3, y is 0.6858999729156494\n",
      "before step 4, y is 0.651604950428009\n",
      "before step 5, y is 0.6190246939659119\n",
      "before step 6, y is 0.5880734324455261\n",
      "before step 7, y is 0.5586697459220886\n",
      "before step 8, y is 0.5307362675666809\n",
      "before step 9, y is 0.5041994452476501\n"
     ]
    }
   ],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to see how quickly the output decreases by looking at this long list. The TensorBoard helps us by providing a nice plot using FileWriter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"log_simple_stats\")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "summary_y = tf.summary.scalar('output', y)\n",
    "for i in range(100):\n",
    "    summary_str = sess.run(summary_y)\n",
    "    file_writer.add_summary(summary_str, i)\n",
    "    sess.run(train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up the TensorBoard and we'll see the plot.\n",
    "![log_simple_stats](https://github.com/chauvm/tensorflow_tutorials/raw/master/images/log_simple_stats.png \"TensorBoard's diagram of our training progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More resources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Activation_function\n",
    "\n",
    "https://www.tensorflow.org/tutorials/\n",
    "\n",
    "https://www.tensorflow.org/how_tos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
