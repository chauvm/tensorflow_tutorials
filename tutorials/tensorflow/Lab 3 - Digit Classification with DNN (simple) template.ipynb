{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple network to classify handwritten digits\n",
    "\n",
    "\n",
    "Trong lab 3, chúng ta sẽ xây dựng những neural network đơn giản để phân loại các chữ số viết tay trong kho dữ liệu MNIST.\n",
    "\n",
    "Phần 1: neural network này sẽ chỉ có input layer và output layer. Ta sẽ sử dụng softmax regression cho output layer, và hàm cross entropy khi tính loss function. Với cách chọn hàm như vậy, network này hoàn toàn tương đồng với thuật toán logistic regression cho nhiều loại trong lab trước.\n",
    "\n",
    "Phần 2: bài tập thêm vào neural network ở phần 1 một hidden layer ở giữa input và output layer.\n",
    "\n",
    "Phần 3: bài tập thêm hidden layer nữa vào network ở phần 2.\n",
    "\n",
    "Slide đi kèm: https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Network với input và output layer\n",
    "### 1.1 Khái quát\n",
    "(Dựa theo https://www.tensorflow.org/get_started/mnist/beginners)\n",
    "Trong phần này, chúng ta sẽ xây dựng một network không có hidden layer mà chỉ có input layer gồm 784 neuron được kết nối thẳng đến output layer gồm 10 neuron tương ứng với 10 nhóm chữ số viết tay.\n",
    "\n",
    "<img src=\"../../images/graphs/neural_network_0_hidden_layer.png\"/>\n",
    "\n",
    "Kết quả của 10 neuron này sẽ được biến đổi ở bước softmax regression để cuối cùng ta thu được 10 giá trị xác suất (là các số thực dương và tổng là 1) ứng với xác suất mỗi hình ảnh thuộc về từng nhóm chữ số. Cuối quá trình học, hình ảnh sẽ được network gắn cho nhóm chữ số mà xác suất hình ảnh này ứng với nhóm đó là cao nhất trong 10 giá trị xác suất.\n",
    "\n",
    "Sai số giữa label dự đoán và label thật được tính bằng hàm cross entropy. Một lần nữa chúng ta sẽ dùng $GradientDescentOptimizer$ để thay đổi $weight$ và $bias$ giữa input layer và output layer, sao cho sai số này là nhỏ nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Xây dựng network\n",
    "Network đơn giản này được xây dựng tương tự như Logistic Regression cho 10 nhóm trong lab trước. Chú ý cách sử dụng $Dataset.next\\_batch()$ để lấy một nhóm nhỏ data đưa vào $train\\_step$. Theo bạn tại sao chúng ta làm như vậy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "with tf.name_scope(\"Input\") as scope:\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"x-input\")               \n",
    "    y_correct = tf.placeholder(tf.float32, [None, 10], name=\"y-correct_label\")\n",
    "    \n",
    "with tf.name_scope(\"Weight\") as scope:\n",
    "    W = tf.Variable(tf.zeros([784, 10]), name=\"weight\")                       \n",
    "    \n",
    "with tf.name_scope(\"Bias\") as scope:\n",
    "    b = tf.Variable(tf.zeros(10), name=\"bias\")                                \n",
    "    \n",
    "with tf.name_scope(\"Softmax\") as scope:\n",
    "    y = tf.nn.softmax(tf.matmul(x, W) + b, name=\"softmax\")                      # * \n",
    "    \n",
    "with tf.name_scope(\"Cross_Entropy\") as scope:                                   # *\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_correct * tf.log(y), reduction_indices=[1]), name=\"cross_entropy\")\n",
    "    \n",
    "with tf.name_scope('Train') as scope:\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "    \n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_correct,1), name = \"correct_prediction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Launch the model\n",
    "sess = tf.InteractiveSession()\n",
    "file_writer = tf.summary.FileWriter(\"DNN_0_hidden_layer\", sess.graph)\n",
    "# create a summary for our cost and accuracy\n",
    "tf.summary.scalar(\"cost_summary\", cross_entropy)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# merge all summaries into a single operation which we can execute in a session \n",
    "summary_step = tf.summary.merge_all()\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)                         #batch_size = 100\n",
    "    _, summary = sess.run([train_step, summary_step], feed_dict={x: batch_xs,y_correct: batch_ys})\n",
    "    \n",
    "    # logging\n",
    "    file_writer.add_summary(summary, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*: 2 bước này được viết tách biệt để thấy rõ trình tự các bước. Khi viết code bằng TensorFlow nên sử dụng $tf.nn.softmax\\_cross\\_entropy\\_with\\_logits$ trực tiếp lên $tf.matmul(x, W) + b$ như giải thích trong https://www.tensorflow.org/get_started/mnist/beginners#training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network với 1 hidden layer\n",
    "### 2.1 Khái quát\n",
    "<img src=\"../../images/graphs/neural_network_1_hidden_layer.png\"/>\n",
    "\n",
    "Chúng ta sẽ thêm vào network đơn giản ở trên 1 hidden layer nữa. Đầu tiên hãy chọn số neuron cho lớp ẩn này - một số nguyên bất kì $neuron\\_1$, chúng ta sẽ thay đổi số nguyên này sau khi xây dựng model hoàn chỉnh.\n",
    "\n",
    "<b>Trả lời:</b> $neuron\\_1$ = ?\n",
    "\n",
    "#### Input layer đến hidden layer\n",
    "##### Inputs\n",
    "Hãy mô tả shape của các vector sau:\n",
    "* input $X$\n",
    "* weight $W\\_1$\n",
    "* bias $b\\_1$\n",
    "* weighted sum $z$\n",
    "* hidden layer result $a$\n",
    "\n",
    "##### Activation function\n",
    "Chọn một trong các activation function sau đây: linear, sigmoid ($tf.sigmoid$), hyperbolic tangent, ReLU ($tf.nn.relu$).\n",
    "\n",
    "<b>Trả lời:</b> Activation function?\n",
    "\n",
    "\n",
    "#### Hidden layer đến output layer\n",
    "##### Inputs\n",
    "Hãy mô tả shape của các vector sau:\n",
    "* hidden layer result $a$\n",
    "* weight $W\\_2$\n",
    "* bias $b\\_2$\n",
    "* weighted sum $z$\n",
    "* output $y$\n",
    "\n",
    "##### Activation function\n",
    "Activation function ở output layer có thể là bất kì activation function nào liệt kê ở trên, tuy nhiên softmax thường được sử dụng. \n",
    "\n",
    "<i>Lưu ý cách dùng $tf.nn.softmax\\_cross\\_entropy\\_with\\_logits$ trong TensorFlow.</i> \n",
    "\n",
    "#### Cost/Loss Function, Optimizer\n",
    "\n",
    "Cross entropy loss function\n",
    "\n",
    "$H_{y'}(y) = -\\sum_i y'_i \\log(y_i)$\n",
    "\n",
    "TensorFlow cung cấp sẵn một số optimizers, $GradientDescentOptimizer$ chỉ là một trong số đó: https://www.tensorflow.org/api_guides/python/train#Optimizers.\n",
    "\n",
    "Chọn một trong các optimizers sau: GradientDescentOptimizer, AdamOptimizer, AdadeltaOptimizer.\n",
    "\n",
    "<b>Trả lời:</b> Optimizer?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Xây dựng network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Đầu tiên, import các thư viện cần thiết và dữ liệu MNIST như các lab trước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import tensorflow, matplotlib, load MNIST dataset (one_hot=True)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các tham số trong training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training params\n",
    "neuron_1 = \n",
    "num_iterations = \n",
    "batch_size = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "Khởi tạo tensor $x$ và $y\\_correct$, chứa ảnh và label đúng của dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Input\") as scope:\n",
    "    x = \n",
    "    y_correct ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input layer -> Hidden layer\n",
    "Khởi tạo weight $W\\_1$, bias $b\\_1$, và tính weighted sum $z\\_1$, hidden layer output $a$. Lưu ý khi khởi tạo weight và bias, ta có thể dùng $tf.random\\_normal(shape)$ thay vì $tf.zeros(shape)$ để các giá trị ban đầu của các tham số là khác nhau. Xem thêm https://www.tensorflow.org/api_docs/python/tf/random_normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Input_to_Hidden_layer\") as scope:\n",
    "    W_1 = \n",
    "    b_1 = \n",
    "    z_1 = \n",
    "    a = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layer -> Output layer\n",
    "Khởi tạo weight $W\\_2$, bias $b\\_2$, và tính label dự đoán $y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hidden_Layer_to_Output\") as scope:\n",
    "    W_2 = \n",
    "    b_2 = \n",
    "    y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "Hãy định nghĩa hàm sai số cost/loss function dựa trên label thật $y\\_correct$ và label dự đoán $y$. Chú ý xem $y$ đã được normalized chưa ở bước trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Cost_function\") as scope:\n",
    "    cost ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chọn một optimizer để điều chỉnh thông số trong network sao cho $cost$ ở trên giảm đi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Train') as scope:\n",
    "    train_step ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, định nghĩa hàm tính độ chính xác của thuật toán dự trên label thật $y\\_correct$ và label dự đoán $y$ (của bất kì dataset nào, training/validation/test), tương tự như trong lab trước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_correct,1), name = \"correct_prediction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch\n",
    "Khởi tạo session và chạy thuật toán. Ở bước này, bạn nên copy code sang một file \".py\". và chạy file này.\n",
    "\n",
    "Dưới đây là một ví dụ cách chạy thuật toán và log kết quả biểu diễn trên TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the model\n",
    "sess = tf.InteractiveSession()\n",
    "file_writer = tf.summary.FileWriter(\"DNN_1_hidden_layer_graphs\", sess.graph)\n",
    "# create a summary for our cost and accuracy\n",
    "tf.summary.scalar(\"cost_summary\", cost)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# merge all summaries into a single operation which we can execute in a session \n",
    "summary_step = tf.summary.merge_all()\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    _, summary = sess.run([train_step, summary_step], feed_dict={x: batch_xs,y_correct: batch_ys})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Accuracy validation: {}\".format(accuracy.eval(feed_dict = {x: mnist.validation.images, y_correct: mnist.validation.labels})))\n",
    "    # logging\n",
    "    file_writer.add_summary(summary, i)\n",
    "print(\"Accuracy: {}\".format(accuracy.eval(feed_dict = {x: mnist.test.images, y_correct: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Bài tập:</b> Hãy thay đổi giá trị của số lần lặp, tốc độ học, optimizer, cost function, activation function... và ghi chép lại kết quả thu được. Các số liệu này sẽ giúp ích cho các lab sau và final project. Hãy plot một trong những ảnh mà network này không phân loại đúng, one-hot vector mà network dự đoán cho ảnh này là gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Network với nhiều hidden layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Bài tập:</b> Hãy thêm hidden layers vào network ở trên, và theo dõi tốc độ học và độ chính xác của network mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
