{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Logistic Regression\n",
    "## Trại hè Toán và Khoa học MaSSP\n",
    "Trong lab này, chúng ta sẽ học cách dùng logistic regression để phân loại 2 nhóm chữ số viết tay \"0\" và \"1\".\n",
    "\n",
    "Cách viết code trong Phần 1 dựa vào công thức đã học trong bài giảng về logistic regression, đặc biệt dành cho trường hợp có 2 nhóm cần phân loại.\n",
    "\n",
    "Cách viết code trong Phần 2 chỉ thay đổi một chút cách tính hàm loss function, chiều của tensor, nhưng có thể áp dụng cho phân loại nhiều hơn 2 nhóm.\n",
    "\n",
    "Phần bài tập sẽ là thay đổi code và thông số của Phần 2 để có thể phân loại tất cả 10 nhóm chữ số viết tay từ \"0\" đến \"9\" với độ chính xác cao."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression cho 2 nhóm\n",
    "## 1.1 Tóm tắt\n",
    "<b>0. Lấy dữ liệu cho training set và test set</b>\n",
    "\n",
    "Sử dụng MNIST dataset có thể download qua thư viện TensorFlow, lọc ra các hình ảnh của chữ số \"0\" và \"1\".\n",
    "\n",
    "<b>1. Tính output</b>\n",
    "\n",
    "Thay $\\theta$ bằng $W$, $\\theta_0$ bằng $b$. Các giá trị ban đầu của $W$ và $b$ gán bằng 0.\n",
    "$$z = x* W + b$$\n",
    "\n",
    "$$y = sigmoid(z) = \\frac{1}{1 + exp(-z)}$$  \n",
    "\n",
    "<b>2. Tính loss function, so sánh output với label chuẩn</b>\n",
    "\n",
    "$$cost = -\\frac{1}{m}(y\\_correct*log(y) + (1-y\\_correct)*log(1-y))$$\n",
    "\n",
    "<b>3. Dùng Gradient descent để điều chỉnh $W$ và $b$ sao cho $cost$ nhỏ nhất</b>\n",
    "\n",
    "Sử dụng hàm $GradientDescentOptimizer$ của TensorFlow!\n",
    "\n",
    "<b>4. Lặp lại các bước 1-3 cho đến khi đạt được độ chính xác mong muốn</b>\n",
    "\n",
    "* Training error: tỉ lệ phân loại sai trong training set\n",
    "* Test error: tỉ lệ phân loại sai trong test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tải dữ liệu\n",
    "MNIST dataset chứa các ảnh của các chữ số viết tay có kích thước 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.core.display import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm $read_data_sets$ dùng để tải dữ liệu, tùy vào arguments mà format của dữ liệu sẽ khác nhau. Ví dụ nếu ta đặt $one\\_hot=True$, thì mỗi label nhận được sẽ có chiều 1x10, với giá trị 1 tại vị trí tương ứng với chữ số đó, và 0 cho các vị trí còn lại. Ví dụ, số \"1\" sẽ được biếu diễn bởi array sau:\n",
    "$$[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]$$\n",
    "\n",
    "Tuy nhiên trong phần 1, chúng ta chỉ làm việc với 2 chữ số \"0\" và \"1\", nên chỉ cần label có giá trị 0 ứng với chữ số \"0\" và giá trị 1 với chữ số \"1\" là được. Chúng ta thậm chí không cần cung cấp giá trị $one\\_hot=False$, vì đây là giá trị default của $one\\_hot$ trong hàm $read_data_sets$ rồi.\n",
    "\n",
    ">Hãy kiểm chính bằng cách tìm hàm $read\\_data\\_sets$ trong https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000000005338EB8>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000000005338EF0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000000009ECBAC8>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu tải về được chứa trong thư mục MNIST_data/ và được load vào $mnist$. $mnist$ chứa 3 Dataset: train, validation, và test. \n",
    ">Tìm hiểu thêm về TensorFLow's Dataset class:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_data, validation_data, test_data) = (mnist.train, mnist.validation, mnist.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mỗi Dataset này đều có $images$ và $labels$, chứa các hình ảnh 28x28 và loại tương ứng (cũng là các số từ 0-9).\n",
    "\n",
    ">Hãy tìm size của mỗi Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy lọc ra hình ảnh và label tương ứng của các chữ số \"0\" và \"1\" trong training và test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_images = np.array([train_data.images[i] for i in np.where(train_data.labels[i] == 0 or train_data.labels[i] == 1 for i in range(55000))])\n",
    "train_images = train_data.images[train_data.labels <= 1]\n",
    "train_labels = train_data.labels[train_data.labels <= 1]\n",
    "\n",
    "validation_images = validation_data.images[validation_data.labels <= 1]\n",
    "validation_labels = validation_data.labels[validation_data.labels <= 1]\n",
    "\n",
    "test_images = test_data.images[test_data.labels <=1]\n",
    "test_labels = test_data.labels[test_data.labels <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11623, 784), (2115, 784), (11623,), (2115,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.reshape((-1, 1)).astype(dtype=\"float32\")\n",
    "validation_labels = validation_labels.reshape((-1, 1)).astype(dtype=\"float32\")\n",
    "test_labels = test_labels.reshape((-1, 1)).astype(dtype=\"float32\")\n",
    "train_labels = train_labels.astype(dtype=\"float32\")\n",
    "validation_labels = validation_labels.astype(dtype=\"float32\")\n",
    "test_labels = test_labels.astype(dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11623, 784), (2115, 784), (11623, 1), (2115, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       ..., \n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy plot hình ảnh đầu tiên trong training set và kiểm tra xem label tương ứng có phù hợp với hình ảnh thu được hay không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADBdJREFUeJzt3W+oXPWdx/H3Vzd9YvvAbK4h2OumoiyIsilcghBZunRb\nbajEPlCaByErYVOwlhb6oMF9sIJPZNm2FFkq6Rqaatd2JRXzIOyiQZDCUryK65/qrllJ04SY3KAk\nVoT8++6Deyy3emfudebMnLn5vl8wzJnzO3POl3PzyTlzfmfmF5mJpHou67oASd0w/FJRhl8qyvBL\nRRl+qSjDLxVl+KWiDL9UlOGXivqzcW5szZo1uX79+nFuUirl8OHDnDp1Kpaz7FDhj4jbgB8BlwP/\nmpkP9lt+/fr1zM7ODrNJSX3MzMwse9mBT/sj4nLgX4CvADcAWyPihkHXJ2m8hvnMvxE4lJlvZeZZ\n4BfAlnbKkjRqw4T/auD3C14fbeb9iYjYGRGzETE7Nzc3xOYktWnkV/szc3dmzmTmzNTU1Kg3J2mZ\nhgn/MWB6wevPNvMkrQDDhP954PqI+FxEfAr4OrC/nbIkjdrAXX2ZeT4i7gX+k/muvj2Z+VprlUka\nqaH6+TPzAHCgpVokjZG390pFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfil\nogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9U1FiH6NbKs2vXrr7tDz30UN/2N954o2fb\n9PR0zzaNnkd+qSjDLxVl+KWiDL9UlOGXijL8UlGGXypqqH7+iDgMvAdcAM5n5kwbRWlyXHfddX3b\nP/jgg77tR44c6dlmP3+32rjJ528y81QL65E0Rp72S0UNG/4EnomIFyJiZxsFSRqPYU/7b8nMYxFx\nFfB0RLyRmc8tXKD5T2EnwDXXXDPk5iS1Zagjf2Yea55PAk8CGxdZZndmzmTmzNTU1DCbk9SigcMf\nEVdExGc+nAa+DLzaVmGSRmuY0/61wJMR8eF6/i0z/6OVqiSN3MDhz8y3gL9qsRZNoKX6+Zfy8MMP\n92zbtGnTUOvWcOzqk4oy/FJRhl8qyvBLRRl+qSjDLxXlT3drpFatWtV1CerBI79UlOGXijL8UlGG\nXyrK8EtFGX6pKMMvFWU/v/p67LHHhnr/jh07WqpEbfPILxVl+KWiDL9UlOGXijL8UlGGXyrK8EtF\n2c9f3NGjR/u2P/roo33br7rqqr7tGzd+bBAnTQiP/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9U1JL9\n/BGxB/gqcDIzb2zmrQZ+CawHDgN3Zea7oytTo3L+/Pm+7efOnevbftll/Y8f/m7/5FrOkf+nwG0f\nmbcLOJiZ1wMHm9eSVpAlw5+ZzwHvfGT2FmBvM70XuKPluiSN2KCf+ddm5vFm+m1gbUv1SBqToS/4\nZWYC2as9InZGxGxEzM7NzQ27OUktGTT8JyJiHUDzfLLXgpm5OzNnMnNmampqwM1Jatug4d8PbG+m\ntwNPtVOOpHFZMvwR8TjwX8BfRsTRiNgBPAh8KSLeBP62eS1pBVmynz8zt/Zo+mLLtagDTzzxRNcl\nqCPe4ScVZfilogy/VJThl4oy/FJRhl8qyp/uLu7YsWNdl6COeOSXijL8UlGGXyrK8EtFGX6pKMMv\nFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilovw+/yXuwoULfdsPHTo01Po3btw41PvV\nHY/8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1TUkv38EbEH+CpwMjNvbObdD/w9MNcsdl9mHhhVkRrc\nuXPn+rYfODDcn23z5s1DvV/dWc6R/6fAbYvM/2FmbmgeBl9aYZYMf2Y+B7wzhlokjdEwn/m/FREv\nR8SeiLiytYokjcWg4f8xcC2wATgOfL/XghGxMyJmI2J2bm6u12KSxmyg8Gfmicy8kJkXgZ8APb/d\nkZm7M3MmM2empqYGrVNSywYKf0SsW/Dya8Cr7ZQjaVyW09X3OPAFYE1EHAX+EfhCRGwAEjgMfGOE\nNUoagSXDn5lbF5n9yAhq0QicPn16pOu/9dZbR7p+jY53+ElFGX6pKMMvFWX4paIMv1SU4ZeK8qe7\nL3EPPPDAUO/ftm1b3/bp6emh1q/ueOSXijL8UlGGXyrK8EtFGX6pKMMvFWX4paLs57/E7du3b6j3\nr169um/7ZZd5/Fip/MtJRRl+qSjDLxVl+KWiDL9UlOGXijL8UlH2818C3n///Z5tZ8+e7fvezGy7\nHK0QHvmlogy/VJThl4oy/FJRhl8qyvBLRRl+qagl+/kjYhr4GbAWSGB3Zv4oIlYDvwTWA4eBuzLz\n3dGVql7uvffenm3vvtv/TxIRfdvvvvvugWrS5FvOkf888N3MvAG4GfhmRNwA7AIOZub1wMHmtaQV\nYsnwZ+bxzHyxmX4PeB24GtgC7G0W2wvcMaoiJbXvE33mj4j1wOeB3wBrM/N40/Q28x8LJK0Qyw5/\nRHwa2Ad8JzPPLGzL+RvEF71JPCJ2RsRsRMzOzc0NVayk9iwr/BGxivng/zwzf9XMPhER65r2dcDJ\nxd6bmbszcyYzZ6amptqoWVILlgx/zF8OfgR4PTN/sKBpP7C9md4OPNV+eZJGZTlf6d0EbANeiYiX\nmnn3AQ8C/x4RO4DfAXeNpkSdOXOmb/uzzz478LrvvPPOvu033XTTwOvWZFsy/Jn5a6BXZ/AX2y1H\n0rh4h59UlOGXijL8UlGGXyrK8EtFGX6pKH+6ewU4ffp03/YjR44MvO577rmnb/tSX/nVyuWRXyrK\n8EtFGX6pKMMvFWX4paIMv1SU4ZeKsp//Enf77bf3bb/55pvHVIkmjUd+qSjDLxVl+KWiDL9UlOGX\nijL8UlGGXyrKfv4VYHp6um/7xYsXx1SJLiUe+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pqCXDHxHT\nEfFsRPw2Il6LiG838++PiGMR8VLz2Dz6ciW1ZTk3+ZwHvpuZL0bEZ4AXIuLppu2HmfnPoytP0qgs\nGf7MPA4cb6bfi4jXgatHXZik0fpEn/kjYj3weeA3zaxvRcTLEbEnIq7s8Z6dETEbEbNzc3NDFSup\nPcsOf0R8GtgHfCczzwA/Bq4FNjB/ZvD9xd6XmbszcyYzZ6amplooWVIblhX+iFjFfPB/npm/AsjM\nE5l5ITMvAj8BNo6uTEltW87V/gAeAV7PzB8smL9uwWJfA15tvzxJo7Kcq/2bgG3AKxHxUjPvPmBr\nRGwAEjgMfGMkFUoaieVc7f81sNgg7QfaL0fSuHiHn1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfil\nogy/VJThl4oy/FJRhl8qyvBLRRl+qajIzPFtLGIO+N2CWWuAU2Mr4JOZ1NomtS6wtkG1WdtfZOay\nfi9vrOH/2MYjZjNzprMC+pjU2ia1LrC2QXVVm6f9UlGGXyqq6/Dv7nj7/UxqbZNaF1jboDqprdPP\n/JK60/WRX1JHOgl/RNwWEf8TEYciYlcXNfQSEYcj4pVm5OHZjmvZExEnI+LVBfNWR8TTEfFm87zo\nMGkd1TYRIzf3GVm60303aSNej/20PyIuB/4X+BJwFHge2JqZvx1rIT1ExGFgJjM77xOOiL8G/gD8\nLDNvbOb9E/BOZj7Y/Md5ZWZ+b0Jqux/4Q9cjNzcDyqxbOLI0cAfwd3S47/rUdRcd7LcujvwbgUOZ\n+VZmngV+AWzpoI6Jl5nPAe98ZPYWYG8zvZf5fzxj16O2iZCZxzPzxWb6PeDDkaU73Xd96upEF+G/\nGvj9gtdHmawhvxN4JiJeiIidXReziLXNsOkAbwNruyxmEUuO3DxOHxlZemL23SAjXrfNC34fd0tm\nbgC+AnyzOb2dSDn/mW2SumuWNXLzuCwysvQfdbnvBh3xum1dhP8YML3g9WebeRMhM481zyeBJ5m8\n0YdPfDhIavN8suN6/miSRm5ebGRpJmDfTdKI112E/3ng+oj4XER8Cvg6sL+DOj4mIq5oLsQQEVcA\nX2byRh/eD2xvprcDT3VYy5+YlJGbe40sTcf7buJGvM7MsT+Azcxf8f8/4B+6qKFHXdcC/908Xuu6\nNuBx5k8DzzF/bWQH8OfAQeBN4Blg9QTV9ijwCvAy80Fb11FttzB/Sv8y8FLz2Nz1vutTVyf7zTv8\npKK84CcVZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qaj/B2vpwFakg1ngAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd20fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0].reshape((28,28)), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Viết chương trình phân loại"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "Để thể hiện graph trên Tensorboard rõ ràng hơn, hãy định nghĩa các tensors sau trong scope \"Inputs\":\n",
    "- $x$: chứa tất cả các ảnh trong training set, $tf.placeholder$ có type là $float32$\n",
    "- $y\\_corect$: chứa labels của các ảnh trong training set, $tf.placeholder$ có type là $float32$\n",
    "- $W$: chứa các hệ số tương ứng với từng điểm ảnh, $tf.Variable$\n",
    "- $b$: bias hay $\\theta_0$ trong bài giảng, $tf.Variable$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Inputs\") as scope:\n",
    "    x = tf.placeholder(tf.float32, [None, 784])                   # train_images 55000, 784 pixels, 0-1\n",
    "                                                                  # test_images 10000x784\n",
    "                                                                  # validation_images 5000x784\n",
    "    y_correct = tf.placeholder(tf.float32, [None, 1])             # train_labels: 55000...\n",
    "    W = tf.Variable(tf.zeros([784, 1]))\n",
    "    b = tf.Variable(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis function\n",
    "Hãy viết công thức tính $y$ dựa vào $W$ và $b$.\n",
    "\n",
    "$$z = x* W + b$$\n",
    "\n",
    "$$y = sigmoid(z) = \\frac{1}{1 + exp(-z)}$$\n",
    "\n",
    "Lưu ý $y$ không phải chỉ bao gồm các số 0 và 1 - tương ứng với label \"0\" và \"1\", mà là các giá trị số thực từ 0 đến 1. Giá trị càng gần 1 thì khả năng label là \"1\" càng cao, và giá trị càng gần 0 thì khả năng label là \"1\" càng thấp (hay nói cách khác khả năng label là \"0\" càng cao)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Outputs\") as scope:\n",
    "    y = tf.sigmoid(tf.matmul(x, W) + b)   # x*W = 55000 x 1, b = 1x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "Hãy viết công thức tính $cost$ thể hiện sai số giữa kết quả dự đoán $y$ và label thật $y\\_corect$. Lưu ý rằng giá trị thu được từ operation $cost$ không phải là một array như $y$ hay $y\\_correct$ mà là một số thực.\n",
    "\n",
    "$$cost = -\\frac{1}{m}(y\\_correct*log(y) + (1-y\\_correct)*log(1-y))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Cost\") as scope:\n",
    "    #cost = -tf.reduce_mean((y_correct*tf.log(y)) + ((1-y_correct)*tf.log(1-y)))\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.relu(tf.matmul(x, W) + b)  - \\\n",
    "                        y_correct * (tf.matmul(x, W) + b) + \\\n",
    "                        tf.log(1 + tf.exp(-abs(tf.matmul(x, W) + b)))) #/ tf.cast(tf.shape(y_correct)[0], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "Hãy dùng $GradientDescentOptimizer()$ của TensorFlow để viết operation $train\\_step$ tương tự như trong lab đầu tiên về TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Train') as scope:\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate=0.4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model\n",
    "Trong quá trình training, chúng ta cần biết độ chính xác của phân loại để điều chỉnh thuật toán và tham số cho phù hợp. Như đã nói ở trên, các giá trị trong $y$ dao động từ 0 đến 1, ta cần quyết định label dự đoán cho mỗi ảnh là 0 hoặc 1 dựa vào các giá trị này.\n",
    "\n",
    "Hãy viết một operation có thể tính được độ chính xác của một dataset khi cho biết $y$ và label thật $y\\_correct$ của dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Accuracy\") as scope:\n",
    "    # y_correct 0 or 1, \n",
    "    # y: 0->1, y_a > 0.5 => a = \"1\", y_b = 0.3 => b = \"0\", 0.5 => \"0\"\n",
    "    y_prediction = tf.round(y)\n",
    "    accuracy = 1 - tf.reduce_mean(tf.abs(y_correct - y_prediction))\n",
    "    correct_prediction = tf.equal(tf.round(y_correct), tf.round(y), name=\"correct_prediction\")\n",
    "    misclassified_indices = tf.where(tf.not_equal(correct_prediction, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run session\n",
    "Vậy là chúng ta đã sẵn sàng chạy thuật toán logistic regression!\n",
    "Để kiểm tra phần code trên không mắc các lỗi thường gặp, hãy chạy thử 1 bước $train\\_step$ ở trên. Đừng quên tạo một $InteractiveSession$ và khởi tạo tất cả các biến trước khi chạy bất kì operation nào.\n",
    "\n",
    "Với các tensor được khởi tạo bởi $tf.placeholder$, hãy nhớ cung cấp các giá trị thật cho chúng, ví dụ:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sess.run(operation_name, feed_dict = {x: input_for_x, y: input_for_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "file_writer = tf.summary.FileWriter(\"logistic_regression_graphs\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       ..., \n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       ..., \n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.00594183336943388\n",
      "Misclassifieds in validation: [[314   0]\n",
      " [838   0]]\n",
      "Cost: 0.005868848878890276\n",
      "Misclassifieds in validation: [[314   0]\n",
      " [838   0]]\n",
      "Cost: 0.005799081642180681\n",
      "Misclassifieds in validation: [[314   0]\n",
      " [838   0]]\n",
      "Cost: 0.0057322862558066845\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005668263882398605\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005606809630990028\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005547755863517523\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005490943323820829\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005436226259917021\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005383465439081192\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005332563538104296\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005283379927277565\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005235838703811169\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005189832765609026\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.0051452768966555595\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Cost: 0.005102100782096386\n",
      "Misclassifieds in validation: [[314   0]]\n",
      "Accuracy: 0.9995272159576416\n"
     ]
    }
   ],
   "source": [
    "training_accuracy_summary = tf.summary.scalar(\"Training_accuracy_summary\", accuracy)\n",
    "validation_accuracy_summary = tf.summary.scalar(\"Validation_accuracy_summary\", accuracy)\n",
    "cost_summary = tf.summary.scalar(\"Cost_summary\", cost)\n",
    "\n",
    "for i in range(80):\n",
    "    _, training_accuracy_summary_str = sess.run([train_step, training_accuracy_summary], feed_dict = {x: train_images,\n",
    "                                                                                            y_correct: train_labels })\n",
    "\n",
    "    training_accuracy_summary_str = sess.run(train_step, feed_dict = {x: train_images, \n",
    "                                                                      y_correct: train_labels })\n",
    "    validation_accuracy_summary_str = sess.run(validation_accuracy_summary, feed_dict = {x: validation_images,\n",
    "                                                                                 y_correct: validation_labels})\n",
    "    file_writer.add_summary(training_accuracy_summary_str, i)\n",
    "    file_writer.add_summary(validation_accuracy_summary_str, i)\n",
    "    if i % 5 == 0:\n",
    "        c = sess.run(cost, feed_dict = {x: train_images,\n",
    "                                y_correct: train_labels })\n",
    "        print(\"Cost: {}\".format(c))\n",
    "        misclassifieds = sess.run(misclassified_indices, feed_dict = {x: validation_images,\n",
    "                                                                      y_correct: validation_labels})\n",
    "        print(\"Misclassifieds in validation: {}\".format(misclassifieds))\n",
    "\n",
    "# After training, calculate accuracy of test set\n",
    "print(\"Accuracy: {}\".format(accuracy.eval(feed_dict = {x: test_images, y_correct: test_labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi đảm bảo bước $train\\_step$ chạy như ý, hãy thêm vào các $summary$ tương tự như lab đầu tiên về TensorFlow để theo dõi sự biến thiên của các biến trong TensorBoard, nhất là độ chính xác của thuật toán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression cho nhiều nhóm\n",
    "## 2.1 Tóm tắt\n",
    "Trong phần 1, $y_{(i)}$ thể hiện khả năng một hình ảnh $i$ có label là chữ số \"1\". Do chỉ có 2 nhóm, ta có thể coi $1-y_{(i)}$ là khả năng hình này này có label là chữ số \"0\" và chỉ cần dùng một giá trị $y_{(i)}$ là có thể tính được cả 2 khả năng.\n",
    "\n",
    "Một cách khác để phân loại 2 nhóm là tính hai giá trị $y_{(i)}^0$ và $y_{(i)}^1$ cho mỗi ảnh, giá trị nào cao hơn đồng nghĩa với việc label tương ứng có khả năng đúng cao hơn. Để các giá trị này tương ứng với xác suất, ta có thể dùng $softmax$ để làm $y_{(i)}^0, y_{(i)}^1>0$ và $y_{(i)}^0+y_{(i)}^1 = 1$.\n",
    "\n",
    "Cách này có thể áp dụng cho phân loại nhiều hơn 2 nhóm. Ví dụ nếu có 3 nhóm, ta sẽ tính 3 giá trị $y_{(i)}^0$, $y_{(i)}^1$, và $y_{(i)}^2$, dùng hàm $softmax$ để biến đổi sao cho $y_{(i)}^0, y_{(i)}^1, y_{(i)}^2>0$ và $y_{(i)}^0+y_{(i)}^1+y_{(i)}^2 = 1$. Ảnh sẽ được phân loại theo giá trị cao nhất trong 3 giá trị này.\n",
    "\n",
    "Ngoài ra, khi sử dụng $softmax$, để tính dự đoán $y$, ta không cần áp dụng hàm sigmoid lên $(W*x + b)$ như với trường hợp 2 nhóm. Chi tiết: https://en.m.wikipedia.org/wiki/Softmax_function. \n",
    "\n",
    "## 2.2 Bài tập\n",
    "1. Dựa theo cách phân loại ở phần 1, viết thuật toán phân loại mới như đã mô tả ở trên để phân loại chữ số \"0\" và \"1\"\n",
    "2. Thay đổi thuật toán ở câu trên một lần nữa để phân loại tất cả 10 nhóm các chữ số trong MNIST dataset. Độ chính xác thu được là bao nhiêu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "train_data, test_data = mnist.train, mnist.test\n",
    "\n",
    "learning_rate = 1\n",
    "train_images = train_data.images\n",
    "train_labels = train_data.labels\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10], tf.float32))\n",
    "b = tf.Variable(tf.zeros([10], tf.float32))\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y_correct = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y_correct*tf.log(y), 1))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_correct, 1))\n",
    "   \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "for i in range(200):\n",
    "    _, c = sess.run([optimizer,cost], feed_dict= {x: train_images, y_correct : train_labels })\n",
    "    if (i+1) %5 == 0 :\n",
    "            print(\"{}\".format(c))\n",
    "print(\"Accuracy:{}\".format( accuracy.eval( feed_dict = {x: mnist.test.images, y_correct: mnist.test.labels})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
