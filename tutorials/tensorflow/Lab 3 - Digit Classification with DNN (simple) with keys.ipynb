{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple network to classify handwritten digits\n",
    "\n",
    "\n",
    "\n",
    "Trong lab 3, chúng ta sẽ xây dựng những neural network đơn giản để phân loại các chữ số viết tay trong kho dữ liệu MNIST.\n",
    "\n",
    "Phần 1: neural network này sẽ chỉ có input layer và output layer. Ta sẽ sử dụng softmax regression làm activation function cho output layer, và hàm cross entropy khi tính loss function. Với cách chọn hàm như vậy, network này hoàn toàn tương đồng với thuật toán logistic regression cho nhiều loại trong lab trước.\n",
    "\n",
    "Phần 2: thêm vào neural network ở phần 1 một hidden layer ở giữa input và output layer.\n",
    "\n",
    "Phần 3: bài tập thêm hidden layer nữa vào network ở phần 2.\n",
    "\n",
    "Slide đi kèm: https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Network với input và output layer\n",
    "### 1.1 Khái quát\n",
    "(Dựa theo https://www.tensorflow.org/get_started/mnist/beginners)\n",
    "Trong phần này, chúng ta sẽ xây dựng một network không có hidden layer mà chỉ có input layer gồm 784 neuron được kết nối thẳng đến output layer gồm 10 neuron tương ứng với 10 nhóm chữ số viết tay.\n",
    "\n",
    "TODO: Graph with 1 input and 1 output layer\n",
    "\n",
    "Kết quả của 10 neuron này sẽ được biến đổi ở bước softmax regression để cuối cùng ta thu được 10 giá trị xác suất (là các số thực dương và tổng là 1) ứng với xác suất mỗi hình ảnh thuộc về từng nhóm chữ số. Cuối quá trình học, hình ảnh sẽ được network gắn cho nhóm chữ số mà xác suất hình ảnh này ứng với nhóm đó là cao nhất trong 10 giá trị xác suất.\n",
    "\n",
    "Sai số giữa label dự đoán và label thật được tính bằng hàm cross entropy. Một lần nữa chúng ta sẽ dùng $GradientDescentOptimizer$ để thay đổi $weight$ và $bias$ giữa input layer và output layer, sao cho sai số này là nhỏ nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Xây dựng network\n",
    "Đầu tiên chúng ta hãy load dữ liệu bằng lệnh đã dùng trong lab trước. Lưu ý ta sẽ dùng $one\\_hot$ vector cho labels. Hãy thử đoán xem dạng dữ liệu của labels thay đổi như thế nào với lựa chọn $one\\_hot=True$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000000E3C3AEC50>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000000E3C3AEBE0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000000E3BDD7400>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Input\n",
    "\n",
    "Hãy mô tả shape của các vector sau:\n",
    "* input\n",
    "* weight\n",
    "* bias\n",
    "* output\n",
    "\n",
    "Và khởi tạo input, weight, bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Input\") as scope:\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"x-input\")               # None means a dimension can be of any length\n",
    "    y_correct = tf.placeholder(tf.float32, [None, 10], name=\"y-correct_label\")\n",
    "    \n",
    "with tf.name_scope(\"Weight\") as scope:\n",
    "    W = tf.Variable(tf.zeros([784, 10]), name=\"weight\")                       # weights\n",
    "    \n",
    "with tf.name_scope(\"Bias\") as scope:\n",
    "    b = tf.Variable(tf.zeros(10), name=\"bias\")                                # bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectors (dimension, how to construct these vectors from our data set). What are the examples of incorrect prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>answer:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could be the \"loss function\"? How many variables are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>answer:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why shouldn't we use the number of incorrectly classified images as the loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>answer:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mentors now show our way to construct a neural network for this problem: the use of cross entropy as the loss function, softmax regression as the output layer's activation function. Please note that this is just one of many different ways to solve this classification problem.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the shape of x, W, and b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>answer:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use softmax regression for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Softmax\") as scope:\n",
    "    y = tf.nn.softmax(tf.matmul(x, W) + b, name=\"softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy loss function\n",
    "\n",
    "$H_{y'}(y) = -\\sum_i y'_i \\log(y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Cross_Entropy\") as scope:\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_correct * tf.log(y), reduction_indices=[1]), name=\"cross_entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Train') as scope:\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"digit_classification_1_graphs\", sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy nhìn vào graph thu được và hiểu trình tự của các operations.\n",
    "\n",
    "![digit_classification_1_graph_1](https://github.com/chauvm/tensorflow_tutorials/raw/master/images/digit_classification_1_graph_1.png \"TensorBoard's diagram of simple digit classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Our Model\n",
    "\n",
    "Well, first let's figure out where we predicted the correct label. tf.argmax is an extremely useful function which gives you the index of the highest entry in a tensor along some axis. For example, $tf.argmax(y,\\ 1)$ is the label our model thinks is most likely for each input, while $tf.argmax(y\\_correct,\\ 1)$ is the correct label. We can use tf.equal to check if our prediction matches the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_correct,1), name = \"correct_prediction\")\n",
    "#print(sess.run(correct_prediction, feed_dict={x: mnist.test.images,y_correct: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us a list of booleans. To determine what fraction are correct, we cast to floating point numbers and then take the mean. For example, [True, False, True, True] would become [1,0,1,1] which would become 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Accuracy\"):\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ chạy bước train_step nhiều lần - tính sai số cross_entropy, dùng GradientDescentOptimizer để thay đổi trọng số và thiên lệch, và lặp lại. Với mỗi lần chạy, chúng ta nên lưu lại giá trị sai số và độ chính xác để thấy được chúng thay đổi thế nào trong quá trình học."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a summary for our cost and accuracy\n",
    "tf.summary.scalar(\"cost_summary\", cross_entropy)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# merge all summaries into a single operation which we can execute in a session \n",
    "summary_step = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta có thể chạy thuật toán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    _, summary = sess.run([train_step, summary_step], feed_dict={x: batch_xs,y_correct: batch_ys})\n",
    "    \n",
    "    # logging\n",
    "    file_writer.add_summary(summary, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy dùng TensorBoard để thấy đồ thị sự biến thiên của sai số và độ chính xác theo số lần học.\n",
    "\n",
    "\n",
    "![digit_classification_1_graph_2](https://github.com/chauvm/tensorflow_tutorials/raw/master/images/digit_classification_1_graph_2.png \"TensorBoard's diagram of simple digit classification\")\n",
    "\n",
    "![digit_classification_1_graph_3](https://github.com/chauvm/tensorflow_tutorials/raw/master/images/digit_classification_1_graph_3.png \"TensorBoard's diagram of simple digit classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Độ chính xác của kết quả phân loại cuối cùng là:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9177\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,y_correct: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hãy thay đổi giá trị của số lần lặp và tốc độ học và quan sát kết quả thu được."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>answer:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network với hidden layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
