{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression\n",
    "## MaSSP 2017, Computer Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Chuẩn bị: Xếp Châu__\n",
    "\n",
    "Hướng dẫn theo tutorial https://www.tensorflow.org/get_started/mnist/pros và một số hình ảnh lấy từ https://www.slideshare.net/ssuser06e0c5/explanation-on-tensorflow-example-deep-mnist-for-expert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hãy cùng nhau xây dựng một model phân loại các chữ số viết tay trong MNIST sử dụng mạng lưới CNN như sau:\n",
    "\n",
    "__Convolutional Layer #1__: Áp dụng 32 filters, kích cỡ 5x5x1, sau đó kích hoạt 32 feature maps thu được với ReLU activation function\n",
    "\n",
    "__Pooling Layer #1__: Thực hiện max pooling với một filter kích cỡ 2x2 và stride bằng 2 (như vậy các vùng được áp dụng pooling không bị trùng nhau)\n",
    "\n",
    "__Convolutional Layer #2__: Áp dụng 64 filters, kích cỡ 5x5x32, sau đó là ReLU activation function lên 64 feature maps này\n",
    "\n",
    "__Pooling Layer #2__: Giống pooling layer #1, Thực hiện max pooling với một filter kích cỡ 2x2 và stride bằng 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../../images/TensorFlow_Digit_Classification_with_CNN_Guide/convolution.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Dense Layer #1__: Với 1024 neurons, sử dụng xác suất dropout 0.4 (xác suất 0.4 cho bất kì neuron nào có thể bị bỏ qua trong một bước training)\n",
    "\n",
    "__Dense Layer #2 (Logits Layer)__: 10 neurons, mỗi neuron ứng với một nhóm trong 10 nhóm chữ số 0–9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../../images/TensorFlow_Digit_Classification_with_CNN_Guide/fc_layer.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 0. Load data và các hàm trợ giúp\n",
    "Đầu tiên ta viết các lệnh import quen thuộc và cách load dữ liệu MNIST với $one\\_hot=True$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Chúng ta sẽ viết 2 hàm $weight\\_variable$ và $bias\\_variable$ để thu gọn code khi khởi tạo $weight$ và $bias$ cho mỗi lớp trong CNN. Cụ thể, 2 hàm này sẽ nhận vào kích thước và trả về tensor với kích thước tương ứng.\n",
    "\n",
    "Với $weight$, giá trị của các phần tử thuộc một _distribution_ với _standard deviation_ 0.1. Với $bias$, giá trị ban đầu mỗi phần tử bằng nhau và bằng 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Weight Initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Trong ví dụ này, 2 bước max pooling sử dụng đều filter có kích cỡ 2x2 và giá trị stride là 2, nên ta có thể viết gọn lại thành một hàm $max\\_pool\\_2x2$ nhận vào input feature maps và trả lại kết quả thu được khi gọi hàm $tf.nn.max\\_pool$ với thông số định sẵn.\n",
    "\n",
    "Tương tự, với 2 bước convolution, ta sử dụng stride bằng 1 và $padding=SAME$ để giữ nguyên chiều dài và chiều rộng của input feature maps. Hàm trợ giúp $conv2d$ nhận input feature maps và filter, trả lại kết quả convolution bằng cách gọi hàm $tf.nn.conv2d$ của TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Pooling\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Xây dựng model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.1 Inputs\n",
    "Như các thuật toán khác, ta nhập vào hình ảnh và label tương ứng với các hình ảnh đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "#x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "#y_correct = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Thử với input là 1 ảnh duy nhất từ training set\n",
    "x = tf.constant(mnist.train.images[0])\n",
    "y_correct = tf.constant(mnist.train.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Khác với Deep Neural Network - nhận vào 784 pixel ảnh dưới dạng vector và mất đi tính 2 chiều của ảnh, Convolutional Nueeural Network nhận một hình ảnh 2D vào trong lớp Convolution. Do đó, chúng ta cần \"reshape\" lại hình ảnh.\n",
    "\n",
    "_Lưu ý với chiều có giá trị $-1$, điều này nghĩa là TensorFlow sẽ tự tính giá trị phù hợp cho chiều này bằng cách lấy tổng số phần tử chia cho các giá trị đã cung cấp (28, 28, 1)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 28, 28,  1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.shape(x_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.2 First Convolutional Layer và Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Convolutional Layer #1 Sử dụng 32 filters, mỗi filter có kích cỡ 5x5.\n",
    "\n",
    "Gọi $W\\_conv1$ là ma trận giữ các filter này, ta sẽ dùng hàm $weight\\_variable$ ở trên để khởi tạo $W\\_conv1$. Như ta đã biết, để khởi tạo $weight$, chúng ta cần cung cấp shape của ma trận này.\n",
    "\n",
    "Do mỗi filter có kích cỡ 5x5, 2 giá trị đầu tiên của shape của $W\\_conv1$ là (5, 5).\n",
    "\n",
    "Giá trị của chiều thứ 3 trong shape sẽ ứng với số kênh của $x\\_image$, trong trường hợp này là 1 (do ảnh là đen trắng).\n",
    "\n",
    "Giá trị của chiều thứ 4 trong shape tương ứng với số kênh của mỗi ảnh được tạo ra sau bước convolution #1 này. Do chúng ta sử dụng 32 filters, mỗi filter tạo ra một kênh, nên mỗi ảnh ban đầu sẽ tạo 32 kênh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# First convolutional layer's weight\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mỗi filter lại có một giá trị bias đi kèm. Do đó 32 filters cần một vector bias có shape [32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# First convolutional layer's bias\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sau đó, thực hiện bước convolution:\n",
    "1. Gọi hàm $conv2d$ định nghĩa ở trên, cho $x\\_image$ và $W\\_conv1$\n",
    "2. Cộng bias vào kết quả thu được ở trên\n",
    "3. Gọi hàm ReLU lên kết quả thu được ở trên, thu được $h\\_conv1$ giữ feature maps ở bước Convolutional Layer #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 28, 28, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.shape(h_conv1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Như đã đề cập ở trên, hàm $conv2d$ chúng ta sử dụng không làm thay đổi kích thước độ dài và độ rộng của mỗi feature map, tuy nhiên số kênh lại tăng lên. Ma trận feature maps $h\\_conv1$ có kích thước [số ảnh, 28, 28, 32].\n",
    "\n",
    "Bước Max Pooling #1 sẽ áp dụng hàm $max\\_pool\\_2x2$ cho feature maps $h\\_conv1$. Kết quả là kích thước của mỗi feature map sẽ bị giảm đi 4 lần (một nửa chiều dài, một nửa chiều rộng). Shape của ma trận feature maps $h\\_pool1$ là [số ảnh, 14, 14, 32]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# pooling \n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 14, 14, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.shape(h_pool1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3 Second Convolutional Layer và Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Convolutional Layer #2 sử dụng 64 filter có kích thước dài và rộng là 5x5. Độ sâu của mỗi filter ứng với số kênh của feature maps $h\\_pool1$ - 32. Số chiều lớp convolution này tạo ra là 64 - bằng với số filter. Do đó, shape để khởi tạo weight cho bước này $W\\_conv2$ là [5, 5, 32, 64].\n",
    "\n",
    "Tương tự, shape của bias là [64].\n",
    "\n",
    "Bước Max Pooling #2 giống hệt Max Pooling #1, kích cỡ chiều dài và rộng của mỗi feature map giảm đi một nửa, từ 14x14 còn 7x7. Shape của $h\\_pool2$ là [số ảnh, 7, 7, 64]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7,  7, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.shape(h_pool2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Như vậy kết thúc bước Convolution, mỗi hình ảnh lúc đầu có kích thước 28x28 đã trở thành dạng 7x7x64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.4 Full Connection Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$h\\_pool2$ chưa phải là input trực tiếp đưa vào FC layer - hay đơn giản là một Neural Network ta đã học. Ta cần \"đập dẹt\" feature maps này ra để tạo thành một vector cho mỗi ảnh. Hãy nhớ trong DNN, chúng ta nhập vector 784 pixel của mỗi ảnh vào network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 3136])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.shape(h_pool2_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sau đó ta xây dựng lớp này tương tự như trong DNN. Trong tutorial này, chúng ta có duy nhất một lớp ẩn với số neuron là 1024. Activation function trong lớp này là ReLU cũng giống lớp Convolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Fully connected layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])    \n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 1024])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.shape(h_fc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Một điểm khác biệt duy nhất ở đây là ta sử dụng dropout. Với hàm này, ta cung cấp một xác suất giữ lại neuron $keep\\_prob$, ví dụ nếu $keep\\_prob=0.4$, nghĩa là mỗi neuron sẽ có khả năng 60% bị bỏ qua trong mỗi bước training (kết quả bằng 0).\n",
    "\n",
    "Hãy tham khảo cheatsheet hoặc documentation của TensorFlow để biết thêm cách sử dụng hàm này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuối cùng, ta xây dựng lớp output layer với 10 neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Output layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    " \n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "...Đánh giá và bước học trong model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Cost function\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_correct, logits=y_conv))\n",
    "\n",
    "# Optimization\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# Evaluate model\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_correct,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Chạy model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "Accuracy validation: 0.07500000298023224\n",
      "step 50, training accuracy 0.92\n",
      "Accuracy validation: 0.8899999856948853\n",
      "step 100, training accuracy 0.93\n",
      "Accuracy validation: 0.9100000262260437\n",
      "step 150, training accuracy 0.91\n",
      "Accuracy validation: 0.8949999809265137\n",
      "step 200, training accuracy 0.97\n",
      "Accuracy validation: 0.9200000166893005\n",
      "step 250, training accuracy 0.95\n",
      "Accuracy validation: 0.949999988079071\n",
      "step 300, training accuracy 0.98\n",
      "Accuracy validation: 0.925000011920929\n",
      "step 350, training accuracy 0.98\n",
      "Accuracy validation: 0.9750000238418579\n",
      "step 400, training accuracy 0.96\n",
      "Accuracy validation: 0.9800000190734863\n",
      "step 450, training accuracy 0.99\n",
      "Accuracy validation: 0.9700000286102295\n",
      "step 500, training accuracy 0.98\n",
      "Accuracy validation: 0.9750000238418579\n",
      "Accuracy: 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "# Launch the model\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "file_writer = tf.summary.FileWriter(\"CNN\", sess.graph)\n",
    "# create a summary for our cost and accuracy\n",
    "tf.summary.scalar(\"cost_summary\", cross_entropy)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# merge all summaries into a single operation which we can execute in a session \n",
    "summary_step = tf.summary.merge_all()\n",
    "validation_size = 200\n",
    "for i in range(501):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    if i%50 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch_xs, y_correct: batch_ys, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        valid_xs, valid_ys = mnist.validation.next_batch(validation_size)\n",
    "        print(\"Accuracy validation: {}\".format(accuracy.eval(\n",
    "                feed_dict = {x: valid_xs, y_correct: valid_ys,keep_prob: 1.0 })))\n",
    "    _, summary = sess.run([train_step, summary_step], \n",
    "            feed_dict={x: batch_xs, y_correct: batch_ys, keep_prob: 0.6})\n",
    "    # logging\n",
    "    file_writer.add_summary(summary, i)\n",
    "    \n",
    "print(\"Accuracy: {}\".format(accuracy.eval(feed_dict = {x: mnist.test.images[:validation_size], \n",
    "                                               y_correct: mnist.test.labels[:validation_size], \n",
    "                                               keep_prob: 1.0})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Bài tập\n",
    "Chạy phần code trên với một nhóm nhỏ các hình ảnh vào theo dõi shape của mỗi bước trung gian.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
